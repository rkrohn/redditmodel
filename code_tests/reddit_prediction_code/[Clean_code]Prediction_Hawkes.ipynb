{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from collections import OrderedDict\n",
    "import gc\n",
    "from itertools import islice\n",
    "import time\n",
    "from scipy.optimize import curve_fit, minimize\n",
    "from scipy.special import erf, gamma\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "from operator import itemgetter\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "from copy import deepcopy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload a set of trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this work the preprocessed set of trees is used. Each tree is asssumed to be a networkx Graph (undirected) with key node attributes: 'root': Bool - if the node is the post; 'created': int, POSIX timestamp -- creation time of the node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_filename = './sample_trees.dump'\n",
    "final_tree_list = pickle.load(open (dump_filename, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of all trees sorted by its size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "Otrees_list = sorted(final_tree_list, key=lambda t: nx.number_of_nodes(t), reverse=False)\n",
    "print(len(Otrees_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference of parameters of a process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate parameters of $\\mu(t)$ and $\\phi(t)$ given the time stamps. Initial guess for parameters may be bad for convergence (one of the parameters is larger than in *large_parameters*), thus a random perturbation is introduced (maximum *runs* times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_parameters_estimation(hawkes_root, runs = 10, large_params = [1000, 10000, 20], start_params = [20, 500, 2.3]):\n",
    "    \n",
    "    def weib_loglikelihood(var):  # var = (a,b,alpha)\n",
    "        t_n = hawkes_root[-1]\n",
    "        f = -var[0]*(1-np.exp(-(t_n/var[1])**(var[2]))) + len(hawkes_root)*(np.log(var[0])+np.log(var[2])-(var[2])*np.log(var[1]))\n",
    "        for t in hawkes_root:\n",
    "            f+= (var[2]-1)*np.log(t)-(t/var[1])**(var[2])\n",
    "        return (-1)*f\n",
    "        \n",
    "    param_set = np.asarray(start_params)\n",
    "    for i in range(runs):\n",
    "        result = minimize(weib_loglikelihood, param_set, method = 'L-BFGS-B', \n",
    "                      bounds = ((0.0001,None), (0.0001,None),(0.0001,None)))\n",
    "        fit_params = list(result.get('x'))\n",
    "        if fit_params[0] > large_params[0] or fit_params[1] > large_params[1] or fit_params[2] > large_params[2]:\n",
    "            param_set += np.array([np.random.normal(0, start_params[0]/10), np.random.normal(0, start_params[1]/10),\n",
    "                                  np.random.normal(0, start_params[2]/10)])\n",
    "            if i == runs-1:\n",
    "                fit_params = None\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return fit_params     # [a,b,alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_parameters_estimation(hawkes_others, runs = 10, large_params = [20, 20], start_params = [4.,2.]):\n",
    "\n",
    "    def lognorm_loglikelihood(var): # var = [mu,sigma]\n",
    "        t_n = hawkes_others[-1]\n",
    "        f = (-1/2-(1/2)*erf((np.log(t_n)-var[0])/(np.sqrt(2)*var[1]))) + len(hawkes_others)*np.log(1/(var[1]*np.sqrt(2*np.pi)))\n",
    "        for t in hawkes_others:\n",
    "            f+= -(np.log(t)-var[0])**2/(2*var[1]**2)-np.log(t)\n",
    "        return (-1)*f\n",
    "    \n",
    "    param_set = np.asarray(start_params)\n",
    "    for i in range(runs):\n",
    "        result = minimize(lognorm_loglikelihood, param_set, \n",
    "                                        method = 'L-BFGS-B', \n",
    "                                        bounds = ((0.0001,None), (0.0001,None)))\n",
    "        fit_params = list(result.get('x'))\n",
    "#         print(\"Current params:\", param_set, \n",
    "#                   \"fit_params:\", fit_params,\n",
    "#                   \"L=\", lognorm_loglikelihood(fit_params))\n",
    "        if fit_params[0] > large_params[0] or fit_params[1] > large_params[1]:\n",
    "            param_set += np.array([np.random.normal(0, start_params[0]/10), np.random.normal(0, start_params[1]/10)])\n",
    "            if i == runs-1:\n",
    "                fit_params = None\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return fit_params  # [mu, sigma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_parameters_estimation(tree, root):\n",
    "    f = 1-tree.degree(root)/(nx.number_of_nodes(tree)-1)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we present functions that generate the Poisson process with intensities $\\mu(t)$ and $\\phi(t)$ starting from the *start_time* with *params*. The process ends either 1) when the gap between consecutive events is more than *T* minutes, or 2) when the number of generated events is greater than upper bound *N_max*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mu_poisson_times(start_time, params, T = 7200, N_max = 2000):   # Weibull kernel\n",
    "    (a, b, alpha) = params\n",
    "    def mu_func(t, a, b, alpha): # a>0, b>0, alpha>0  --- Weibull\n",
    "        f = (a*alpha/b)*(t/b)**(alpha-1)*np.exp(-(t/b)**alpha)\n",
    "        return f\n",
    "\n",
    "    thin_poisson_times = []\n",
    "    t = start_time\n",
    "    if alpha>1:\n",
    "        if t>b*((alpha-1)/alpha)**(1/alpha):\n",
    "            lbd = mu_func(t,a,b, alpha)\n",
    "        else:\n",
    "            lbd = (a*alpha/b)*((alpha-1)/alpha)**(1-1/alpha)*np.exp(-((alpha-1)/alpha))\n",
    "    if alpha>0 and alpha<1:\n",
    "        lbd = mu_func(t,a,b,alpha)\n",
    "    while True:\n",
    "        e = np.random.uniform(low=0, high=1)\n",
    "        t += -np.log(e)/lbd\n",
    "        U = np.random.uniform(low=0, high=1)\n",
    "        if U<mu_func(t,a,b, alpha)/lbd:\n",
    "            thin_poisson_times.append(t)\n",
    "            if (alpha>1 and t>b*((alpha-1)/alpha)**(1/alpha)) or (alpha>0 and alpha<1):\n",
    "                lbd = mu_func(t,a,b, alpha)\n",
    "        if len(thin_poisson_times)>0:\n",
    "            if t-thin_poisson_times[-1]>T:\n",
    "                break\n",
    "        else:\n",
    "            if t>T:\n",
    "                break\n",
    "        if len(thin_poisson_times)>N_max:\n",
    "            return thin_poisson_times\n",
    "    return thin_poisson_times\n",
    "\n",
    "def generate_phi_poisson_times(start_time, params, n_b, T = 7200, N_max = 200): # Log-normal kernel\n",
    "    (mu, sigma) = params\n",
    "    def intensity(t, mu, sigma, n_b):\n",
    "        if t>0:\n",
    "            lbd = n_b*(1/(sigma*t*np.sqrt(2*np.pi)))*np.exp(-((np.log(t)-mu)**2)/(2*sigma**2))\n",
    "        else:\n",
    "            lbd = 0\n",
    "        return lbd\n",
    "    thin_poisson_times = []\n",
    "    t = start_time\n",
    "    if t>np.exp(mu-(sigma**2)):  \n",
    "        lbd = intensity(t, mu, sigma, n_b)\n",
    "    else:\n",
    "        lbd = n_b*(np.exp(sigma**2-mu)/(sigma*np.sqrt(2*np.pi)))*np.exp(-(sigma**2)/2)\n",
    "    while True:\n",
    "        e = np.random.uniform(low=0, high=1)\n",
    "        t += -np.log(e)/lbd\n",
    "        U = np.random.uniform(low=0, high=1)\n",
    "        if U<intensity(t, mu, sigma, n_b)/lbd:\n",
    "            thin_poisson_times.append(t)\n",
    "            if t>np.exp(mu-(sigma**2)):\n",
    "                lbd = intensity(t, mu, sigma, n_b)\n",
    "        if len(thin_poisson_times)>0:\n",
    "            if t-thin_poisson_times[-1]>T:\n",
    "                break\n",
    "        else:\n",
    "            if t>T:\n",
    "                break\n",
    "        if len(thin_poisson_times)>N_max:\n",
    "            return thin_poisson_times\n",
    "    return thin_poisson_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below simulates the discussion tree from the initially observed subtree *given_tree*. *Start_time* is the age of the *given_tree* (or t_learn). First we generate comments to already existing comments, then generate further possible comments to the post and their further comments. Tree simulation is successful if the total number of nodes is less than *N_max*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_comment_tree(given_tree, start_time, params_mu, params_phi, n_b, N_max = 2000):\n",
    "    T = 7200  # hard set: maximum possible time gap between consecutive events for root comments\n",
    "    T2 = 7200  # hard set: -//- for comments to comments\n",
    "    g = nx.Graph()\n",
    "    g = given_tree.copy()\n",
    "    root, _ = get_root(g)\n",
    "    root_node_list = []\n",
    "    node_index = max(g.nodes())\n",
    "    comment_node_list = []\n",
    "    further_comment_times = []\n",
    "    for u in g.neighbors(root):\n",
    "        root_node_list.append(u)\n",
    "    for v in g.nodes()[1:]:\n",
    "        if v not in root_node_list:\n",
    "            comment_node_list.append(v)\n",
    "    while len(comment_node_list)>0:\n",
    "        comment_node = deepcopy(comment_node_list[0])\n",
    "        del comment_node_list[0]\n",
    "        comment_time = g.node[comment_node]['created']\n",
    "        further_comment_times.clear()\n",
    "        further_comment_times = generate_phi_poisson_times(float(start_time-comment_time), params_phi, n_b, T2 )\n",
    "        further_comment_times = [i+comment_time for i in further_comment_times]\n",
    "        tree_node_list = []\n",
    "        if len(further_comment_times)>0:\n",
    "            for t in further_comment_times:\n",
    "                node_index += 1\n",
    "                g.add_node(node_index, created = t, root = False)\n",
    "                g.add_edge(comment_node, node_index)\n",
    "                tree_node_list.append(node_index)\n",
    "        while len(tree_node_list)!=0:\n",
    "            current_node = deepcopy(tree_node_list[0])\n",
    "            del tree_node_list[0]\n",
    "            comment_time = g.node[current_node]['created']\n",
    "            further_comment_times = generate_phi_poisson_times(float(start_time-comment_time), params_phi, n_b, T2 )\n",
    "            further_comment_times = [i+comment_time for i in further_comment_times]\n",
    "            if len(further_comment_times)>0:\n",
    "                for t2 in further_comment_times:\n",
    "                    node_index += 1\n",
    "                    g.add_node(node_index, created = t2, root = False)\n",
    "                    g.add_edge(current_node, node_index)\n",
    "                    tree_node_list.append(node_index)\n",
    "                    node_index+=1\n",
    "            if nx.number_of_nodes(g)>N_max:\n",
    "                return g, False   \n",
    "    new_root_comment_times = generate_mu_poisson_times(float(start_time), params_mu, T)\n",
    "    for t in new_root_comment_times:\n",
    "        node_index += 1\n",
    "        g.add_node(node_index, created = t, root = False)\n",
    "        g.add_edge(root, node_index)\n",
    "        tree_node_list = []\n",
    "        new_further_comment_times = generate_phi_poisson_times(0, params_phi, n_b, T2 )\n",
    "        new_further_comment_times = [i+t for i in new_further_comment_times]\n",
    "        if len(new_further_comment_times)>0:\n",
    "            for t2 in new_further_comment_times:\n",
    "                node_index += 1\n",
    "                g.add_node(node_index, created = t2, root = False)\n",
    "                g.add_edge(node_index, node_index)\n",
    "                tree_node_list.append(node_index)\n",
    "        while len(tree_node_list)!=0:\n",
    "            current_node = tree_node_list[0]\n",
    "            del tree_node_list[0]\n",
    "            t_offspring = g.node[current_node]['created']\n",
    "            new_further_comment_times = generate_phi_poisson_times(0, params_phi, n_b, T2 )\n",
    "            new_further_comment_times = [i+t_offspring for i in new_further_comment_times]\n",
    "            if len(new_further_comment_times)>0:\n",
    "                for t2 in new_further_comment_times:\n",
    "                    node_index += 1\n",
    "                    g.add_node(node_index, created = t2, root = False)\n",
    "                    g.add_edge(current_node, node_index)\n",
    "                    tree_node_list.append(node_index)\n",
    "            if nx.number_of_nodes(g)>N_max:\n",
    "                return g, False\n",
    "    return g, True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curve_fit of $\\mu(t)$ (less precise for prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_func_fit_weibull(list_times, res=60, runs = 10, T_max = 3*1440, large_params = [1000, 10000, 20], start_params = [50, 400, 2.3]):\n",
    "    def weib_func(t, a, b, alpha): # a>0, b>0, alpha>0  --- Weibull pdf\n",
    "        return (a*alpha/b)*(t/b)**(alpha-1)*np.exp(-(t/b)**alpha)\n",
    "    \n",
    "    bins = np.arange(0, max([T_max, max(list_times)]), res)\n",
    "    hist, bins = np.histogram(list_times, bins)  # construct histogram of the root comments appearance \n",
    "    center_bins = [b+res/2 for b in bins[:-1]]\n",
    "    \n",
    "    param_set = np.asarray(start_params)\n",
    "    print(\"Start curve_fit estimation:\")\n",
    "    for i in range(runs):\n",
    "        fit_params, pcov = curve_fit(weib_func, xdata = center_bins, ydata = hist/res, p0 = param_set, \n",
    "                                     bounds = (0.0001, 100000))\n",
    "        if fit_params[0] > large_params[0] or fit_params[1] > large_params[1] or fit_params[2] > large_params[2]:\n",
    "            print(\"Current params:\", param_set, \"fit_params:\", fit_params)\n",
    "            param_set += np.array([np.random.normal(0, start_params[0]/10), np.random.normal(0, start_params[1]/10),\n",
    "                                  np.random.normal(0, start_params[2]/4)])\n",
    "            if i == runs-1:\n",
    "                fit_params = [None, None, None]\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return fit_params     # [a,b,alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root(g):\n",
    "    for u in g.nodes():\n",
    "        if (g.node[u]['root']):\n",
    "            return u, g.node[u]['created']\n",
    "    return None\n",
    "\n",
    "def get_root_comment_times(tree):\n",
    "    r, root_time = get_root(tree)\n",
    "    root_comment_times = []\n",
    "    for u in tree.neighbors(r):\n",
    "        root_comment_times.append((tree.node[u]['created'] - root_time)/60)  # in minutes\n",
    "    root_comment_times.sort()\n",
    "    return root_comment_times\n",
    "\n",
    "def get_other_comment_times(tree):\n",
    "    hawkes_others = []\n",
    "    r, root_time = get_root(tree)\n",
    "    sh_paths_dict = nx.shortest_path_length(tree, source=r)\n",
    "    for u, d in sh_paths_dict.items():\n",
    "        if d > 0:\n",
    "            if tree.degree(u)>1:\n",
    "                time_to_add = []\n",
    "                for v in tree.neighbors(u):\n",
    "                    time_to_add.append(tree.node[v]['created'])\n",
    "                time_to_add.sort()\n",
    "                del time_to_add[0]\n",
    "                time_to_add = [(t-tree.node[u]['created'])/60 for t in time_to_add]\n",
    "                hawkes_others = hawkes_others + time_to_add\n",
    "    hawkes_others.sort()\n",
    "    return hawkes_others\n",
    "\n",
    "def get_trunc_tree(tree, trunc_value):\n",
    "    g = nx.Graph()\n",
    "    g = tree.copy()\n",
    "    for u in g.nodes():\n",
    "        if (g.node[u]['root']):\n",
    "            root = u\n",
    "            break\n",
    "    nodes_to_delete = []\n",
    "    for u in g.nodes():\n",
    "        t = (g.node[u]['created']-g.node[root]['created'])/60\n",
    "        if t>trunc_value:\n",
    "            nodes_to_delete.append(u)\n",
    "    for u in nodes_to_delete:\n",
    "        g.remove_node(u)\n",
    "    g_out = nx.convert_node_labels_to_integers(g, first_label=0, ordering='default')\n",
    "    for u in g_out.nodes()[1:]:\n",
    "        g_out.node[u]['created'] = float(g_out.node[u]['created']-g_out.node[0]['created'])/60\n",
    "    g_out.node[0]['created'] = 0.0\n",
    "    return g_out\n",
    "\n",
    "def get_trunc_tree_no_relabel(tree, trunc_value):\n",
    "    g = nx.Graph()\n",
    "    g = tree.copy()\n",
    "    r, root_creation_time = get_root(tree)\n",
    "    nodes_to_delete = []\n",
    "    for u in g.nodes():\n",
    "        t = (g.node[u]['created']-root_creation_time)/60\n",
    "        if t>trunc_value:\n",
    "            nodes_to_delete.append(u)\n",
    "    for u in nodes_to_delete:\n",
    "        g.remove_node(u)\n",
    "    return g\n",
    "\n",
    "def get_size_tree(tree):\n",
    "    return nx.number_of_nodes(tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 13\n",
    "sim_num_runs = 50\n",
    "t_learn_list = ['4h', '6h', '8h', '12h']\n",
    "trunc_values = [240, 360, 480, 720]\n",
    "\n",
    "tree = Otrees_list[i]\n",
    "len(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the main code. Go through *trunc_values*, cut the *tree* into *given_tree* available at the current t_learn from *trunc_values*, infer parameters for $\\mu(t)$ and $\\phi(t)$, grow the tree according to the Hawkes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ---    T_LEARN =  4h    ---\n",
      "Mu_params: [225.575483027062, 484.3164848535451, 0.8332227100362868]\n",
      "Phi_params: [4.05152593111362, 1.2704760083617699]\n",
      "n_b: 0.265625\n",
      "0  of HAWKES trees simulated for the tree i= 13\n",
      "10  of HAWKES trees simulated for the tree i= 13\n",
      "20  of HAWKES trees simulated for the tree i= 13\n",
      "30  of HAWKES trees simulated for the tree i= 13\n",
      "40  of HAWKES trees simulated for the tree i= 13\n",
      "\n",
      "\n",
      "     ---    T_LEARN =  6h    ---\n",
      "Mu_params: [118.5211301087469, 158.31024610782413, 0.9816238718361018]\n",
      "Phi_params: [4.216808701858541, 1.2515096681786082]\n",
      "n_b: 0.2777777777777778\n",
      "0  of HAWKES trees simulated for the tree i= 13\n",
      "10  of HAWKES trees simulated for the tree i= 13\n",
      "20  of HAWKES trees simulated for the tree i= 13\n",
      "30  of HAWKES trees simulated for the tree i= 13\n",
      "40  of HAWKES trees simulated for the tree i= 13\n",
      "\n",
      "\n",
      "     ---    T_LEARN =  8h    ---\n",
      "Mu_params: [134.70936803887108, 211.99711203915194, 0.8891896491314485]\n",
      "Phi_params: [4.449125955250542, 1.2416114470501094]\n",
      "n_b: 0.31176470588235294\n",
      "0  of HAWKES trees simulated for the tree i= 13\n",
      "10  of HAWKES trees simulated for the tree i= 13\n",
      "20  of HAWKES trees simulated for the tree i= 13\n",
      "30  of HAWKES trees simulated for the tree i= 13\n",
      "40  of HAWKES trees simulated for the tree i= 13\n",
      "\n",
      "\n",
      "     ---    T_LEARN =  12h    ---\n",
      "Mu_params: [143.8992422653522, 252.7585253488526, 0.835308054947532]\n",
      "Phi_params: [4.712085673656915, 1.280571100708468]\n",
      "n_b: 0.33333333333333337\n",
      "0  of HAWKES trees simulated for the tree i= 13\n",
      "10  of HAWKES trees simulated for the tree i= 13\n",
      "20  of HAWKES trees simulated for the tree i= 13\n",
      "30  of HAWKES trees simulated for the tree i= 13\n",
      "40  of HAWKES trees simulated for the tree i= 13\n",
      "\n",
      "\n",
      "Sequence done!\n"
     ]
    }
   ],
   "source": [
    "result_dict = {}\n",
    "\n",
    "root, root_creation_time = get_root(tree)\n",
    "\n",
    "result_dict['true_size'] = get_size_tree(tree)\n",
    "list_hawkes_sizes = [[] for i in range(0,len(trunc_values))]\n",
    "\n",
    "run_success = True\n",
    "for t in range(0,len(trunc_values)):\n",
    "    print(\"     ---    T_LEARN = \", t_learn_list[t], \"   ---\")\n",
    "    t_learn = trunc_values[t]\n",
    "    given_tree = get_trunc_tree_no_relabel(tree, t_learn)\n",
    "    if len(given_tree) <= 10:  # break if size of the observed tree is too small for prediction at that moment\n",
    "        print(\"Not enough data for parameters estimation!\")\n",
    "        negative_result = 0\n",
    "        list_hawkes_sizes[t].append(negative_result)\n",
    "        print(\"RUN \" + str(i) + \": T_learn: \"+t_learn_list[t] + \"Not enough data for parameters estimation!\")\n",
    "        run_success = False\n",
    "        continue\n",
    "    root_comment_times = get_root_comment_times(given_tree)\n",
    "    mu_params = mu_parameters_estimation(root_comment_times)\n",
    "    if mu_params == None:  # if loglikelihood estimation fails - use curve_fit\n",
    "        mu_params = mu_func_fit_weibull(root_comment_times)\n",
    "    print(\"Mu_params:\", mu_params)\n",
    "    other_comment_times = get_other_comment_times(given_tree)\n",
    "    phi_params = phi_parameters_estimation(other_comment_times)\n",
    "    print(\"Phi_params:\", phi_params)\n",
    "    n_b = nb_parameters_estimation(given_tree, root)\n",
    "    print(\"n_b:\", n_b)\n",
    "    \n",
    "    hawkes_times = []\n",
    "    given_tree = get_trunc_tree(tree, t_learn)\n",
    "    add_count = sim_num_runs/5\n",
    "    for j in range(0,sim_num_runs):\n",
    "        hawkes_times.clear()\n",
    "        if j%add_count==0:\n",
    "            print(j, \" of HAWKES trees simulated for the tree i=\", i)\n",
    "        sim_tree, success = simulate_comment_tree(given_tree, t_learn, mu_params, phi_params, n_b)\n",
    "        if success:\n",
    "            list_hawkes_sizes[t].append(len(sim_tree))\n",
    "        else:\n",
    "            print('Generation failed! Too many nodes')\n",
    "            print(\"RUN \" + str(i) + \": T_learn: \"+ t_learn_list[t] + ': Generation HAWKES failed! Too many nodes')\n",
    "            list_hawkes_sizes[t] = [-1]\n",
    "            break\n",
    "    print(\"\\n\")\n",
    "result_dict['hawkes_sizes'] = list_hawkes_sizes\n",
    "result_dict[\"run_success\"] = run_success\n",
    "print('Sequence done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the average relative size error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_learn: 4h | avg size error: 0.3245021645021644\n",
      "t_learn: 6h | avg size error: 0.2883116883116883\n",
      "t_learn: 8h | avg size error: 0.15238095238095234\n",
      "t_learn: 12h | avg size error: 0.0601731601731602\n"
     ]
    }
   ],
   "source": [
    "for i, size_list in enumerate(result_dict['hawkes_sizes']):\n",
    "    print(\"t_learn:\", t_learn_list[i], \n",
    "          \"| avg size error:\", np.abs(np.mean(size_list)-result_dict['true_size'])/result_dict['true_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
